<h1 align="center"> AI Robot 3D Simulator</h1>

<p align="center">
  <img src="images/Logo.png" width="150" alt="AI Robot 3D Simulator Logo" />
</p>

<p align="center">
  <b>Advanced Selfâ€‘Learning Industrial Robot Arm Simulation Platform</b><br/>
</p>
<p align="center">
  <img src="https://img.shields.io/badge/Artificial%20Intelligence-AI-blueviolet" />
  <img src="https://img.shields.io/badge/Robotics-Control%20Systems-orange" />
  <img src="https://img.shields.io/badge/Real--Time-3D%20Visualization-brightgreen" />
  <img src="https://img.shields.io/badge/Interactive-Control-blue" />
</p>


<p align="center">
  <a href="https://github.com/dhakarshailendra829/AI_Robot_3D_Simulator"> Star Repository</a> â€¢
  <a href="#-key-capabilities">Key Capabilities</a> â€¢
  <a href="#-system-overview">System Overview</a> â€¢
  <a href="#-architecture--workflow">Architecture</a> â€¢
  <a href="#-screenshots--visuals">Visuals</a> â€¢
  <a href="#-training--learning-pipeline">Training</a> â€¢
  <a href="#-installation--execution">Installation</a>
</p>

---

### Project Overview

**AI Robot 3D Simulator** is a **professionalâ€‘grade robotic arm simulation system** designed to demonstrate how modern **AI models, taskâ€‘level planning, and realâ€‘time visualization** can be integrated into a single cohesive platform.

The simulator enables both **manual control** and **autonomous execution** of industrial robotic tasks such as **pick, place, move, and sort**, using a **behaviorâ€‘cloningâ€“based machine learning model** trained on structured humanâ€“object interaction data.

This project is built as a **portfolioâ€‘ready, industryâ€‘aligned system** that reflects realâ€‘world robotics pipelines â€” from data ingestion and model training to deployment inside an interactive 3D dashboard.

---

## Key Capabilities

### AIâ€‘Driven Motion Learning

* Behavior cloning using deep neural networks (PyTorch)
* Learns joint trajectories from human and object state features
* Generates smooth, continuous jointâ€‘angle predictions

### Intelligent Task Scheduling

* Supports multiple task primitives: `pick`, `place`, `move`, `sort`
* Task queue with autoplay, pause, reset, and stepâ€‘wise execution
* Seamless task transitions for continuous robot operation

### Dual Control Modes

* **Manual Mode**: Direct jointâ€‘level control via UI sliders
* **Autonomous Mode**: Modelâ€‘driven execution using trained AI
* Safe interpolation between joint states

### Realâ€‘Time 3D Visualization

* Live robotic arm animation
* Taskâ€‘wise trajectory rendering
* Visual feedback synchronized with scheduler and model output

### Live Analytics Dashboard

* Realâ€‘time inference monitoring
* Task execution timelines
* System performance insights

---

## System Overview

The simulator provides a **single interactive environment** where users can:

* Train an AI model for robotic motion
* Schedule and execute industrial tasks
* Observe robot behavior in real time
* Analyze model predictions and system performance

**Core system modules:**

* Task Scheduler
* Learning & Inference Engine
* Robot Environment Simulator
* 3D Visualization Engine
* Analytics & Monitoring Layer

---

## Architecture & Workflow

```
Human + Object State Dataset
            â†“
Feature Engineering & Normalization
            â†“
Behavior Cloning Model (PyTorch)
            â†“
Joint Angle Predictions (joint_0 â†’ joint_5)
            â†“
Robot Environment Simulator
            â†“
Realâ€‘Time 3D Visualization & Streamlit UI
```

This modular architecture allows easy extension toward **reinforcement learning**, **physicsâ€‘based simulation**, or **multiâ€‘robot coordination**.

---

## Dataset & Learning Structure

### Input Features

* `timestep`
* `human_0 â€¦ human_44` (human pose & interaction signals)
* `obj_0 â€¦ obj_4` (object state features)

### Target Outputs

* `joint_0 â€¦ joint_5` (robot joint angles)

### Task Metadata

* `task_type` (pick / place / move / sort)

---

## Screenshots & Visuals

<p align="center"><b>Live 3D Robot Arm Visualization</b></p>
<p align="center">
  <img src="images/RobotArm.png" width="760" />
</p>

<p align="center"><b>Task Scheduling & Trajectory Playback</b></p>
<p align="center">
  <img src="images/TaskTrajectory.png" width="760" />
</p>

<p align="center"><b>Analytics & System Monitoring Dashboard</b></p>
<p align="center">
  <img src="images/Analytics.png" width="760" />
</p>

---

## Training & Learning Pipeline

* **Model Type:** Fully Connected Neural Network
* **Learning Method:** Supervised behavior cloning
* **Loss Function:** Mean Squared Error (MSE)
* **Optimizer:** Adam
* **Epochs:** 50
* **Batch Size:** 32

The trained model is persisted for inference:

```
trained_models/imitation_model.pt
```

This approach enables the robot to **imitate expert motion trajectories** and generalize to unseen task configurations.

---

## ðŸ›  Tech Stack (By Role)

### AI / ML Engineering

* Python
* PyTorch
* NumPy
* Pandas
* Matplotlib

### Software Engineering

* Modular Python architecture
* Task schedulers & simulation environments
* Joblib / model persistence

### Visualization & UI

* Streamlit
* Plotly (3D visualization & analytics)
* Custom animation & trajectory rendering

### System Utilities

* OS, SYS
* Time
* psutil (resource monitoring)

---

## Installation & Execution

### Clone Repository

```bash
git clone https://github.com/dhakarshailendra829/AI_Robot_3D_Simulator.git
cd AI_Robot_3D_Simulator
```

### Install Dependencies

```bash
pip install -r requirements.txt
```

### Run Simulator

```bash
streamlit run app.py
```

---

## Future Enhancements

* Reinforcement Learningâ€“based control policies
* Physicsâ€‘aware collision handling
* Multiâ€‘robot coordination
* WebGL / Three.js rendering
* Cloudâ€‘deployed simulation services

---

## ðŸ‘¤ Author

**Shailendra Dhakad**
AI â€¢ Robotics â€¢ Software Systems Engineering

---
